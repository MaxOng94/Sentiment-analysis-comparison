{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training for distilbert transformer\n",
    "Follow this tutorial :https://huggingface.co/transformers/custom_datasets.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from transformers import DistilBertTokenizerFast, Trainer, TrainingArguments, DistilBertForSequenceClassification \n",
    "from sklearn.metrics import accuracy_score, f1_score,precision_score, recall_score,precision_recall_fscore_support\n",
    "from torch.nn.functional import softmax\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = \"../data/label_data.csv\"\n",
    "test_file = \"../data/label_data.csv\"\n",
    "LABEL_COL = \"class\"\n",
    "TEXT_COL = \"comment\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Three utilities functions for transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(fname:str, lower_case: bool=False) ->pd.DataFrame:\n",
    "        \"\"\"\n",
    "        This function will read the textfiles.\n",
    "\n",
    "        fname will be out of new_train_data.csv, unlabeled_data.csv and test_data.txt\n",
    "\n",
    "        \"\"\"\n",
    "        try:\n",
    "            df = pd.read_csv(fname, encoding = \"UTF-8\", usecols = [\"class\",\"comment\"])\n",
    "            df[LABEL_COL]= df[LABEL_COL].replace({\"negative\":0, \"neutral\":1, \"positive\":2})\n",
    "            if lower_case:\n",
    "                df[TEXT_COL]= df[TEXT_COL].str.lower()\n",
    "\n",
    "            return df\n",
    "        except (FileNotFoundError,PermissionError):\n",
    "\n",
    "            print(\"No files found. Check the data directory for files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_utils import customDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_eval(df:pd.DataFrame) -> dict:\n",
    "        # splits to train, val text and labels\n",
    "        \n",
    "        # currently all are pd.Series\n",
    "        train_df,val_df,train_label,val_label = train_test_split(df[\"Truth\"],\n",
    "                                                                 df[\"class\"], \n",
    "                                                                 random_state = 42, \n",
    "                                                                 test_size = 0.2)\n",
    "        \n",
    "        # change all to lists, as inputs to tokenizer has to be \n",
    "        # text input must of type `str` (single example), \n",
    "        #`List[str]` (batch or single pretokenized example) or \n",
    "        #`List[List[str]]` (batch of pretokenized examples).\n",
    "        \n",
    "        train_list = train_df.tolist()\n",
    "        val_list = val_df.tolist()\n",
    "        label_list = train_label.tolist()\n",
    "        val_label_list = val_label.tolist()\n",
    "        \n",
    "        return {\"list of training examples\":train_list,\n",
    "                \"list of val examples\":val_list,\n",
    "                \"list of training labels\":label_list,\n",
    "                \"list of val labels \":val_label_list}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pretrained models and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\",num_labels = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = read_data(test_file, lower_case = True)\n",
    "labels = test_df[LABEL_COL]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before fine-tuning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you call distilbert for sequence classification, you create an additional head on top of the distilbert model. \n",
    "If you don't do any finetuning, the weights of the additional head you create is randomize. THis means that it will perform terribly on our data. \n",
    "We will check the metrics of distilbert that is not fine-tuned and see how it performs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = customDataset(test_encodings, labels)\n",
    "dataloader = DataLoader(dataset = test_dataset, batch_size = 4, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating pre-trained distilbert (not fine tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model.to(device)\n",
    "# model output is logits \n",
    "# return df[\"score\"]\n",
    "# softmax all the logits to class\n",
    "# return df[\"pred\"]\n",
    "\n",
    "test_model.eval()\n",
    "\n",
    "# empty list for prediction to be appended into  \n",
    "pred_list = []\n",
    "with torch.no_grad():  # so will not update \n",
    "    \n",
    "    # tqdm for progress bar\n",
    "    loop = tqdm(enumerate(dataloader), total = len(dataloader),\n",
    "                        leave = True)\n",
    "    for _, data in loop:     \n",
    "        input_ids = data[\"input_ids\"].to(device)\n",
    "        masks = data[\"attention_mask\"].to(device)\n",
    "        labels = data[\"labels\"].to(device)\n",
    "        \n",
    "        outputs = test_model(input_ids, masks, labels = labels)\n",
    "        # information about model outputs: https://huggingface.co/transformers/main_classes/output.html\n",
    "\n",
    "        # sample output: \n",
    "        # SequenceClassifierOutput(loss=tensor(1.6602, device='cuda:0', grad_fn=<NllLossBackward>), \n",
    "        # logits=tensor([[-0.0098,  0.0775,  0.0358,  0.0997, -0.0220],\n",
    "        # [-0.0169,  0.1331,  0.0294,  0.1378,  0.0054]], device='cuda:0',\n",
    "        # grad_fn=<AddmmBackward>), hidden_states=None, attentions=None)\n",
    "   \n",
    "        logits = outputs[\"logits\"]\n",
    "        scores = softmax(logits, dim =1)\n",
    "        # numpy array of batch size \n",
    "        pred = torch.argmax(scores, dim =1).cpu().numpy().tolist()\n",
    "        # appends the batch pred into an empty list \n",
    "        pred_list.append(pred)\n",
    "    \n",
    "    # flatten the nested list in pred_list\n",
    "    flat_list = [item for sublist in pred_list for item in sublist]\n",
    "    \n",
    "    test_df[\"pred\"]= pd.Series(flat_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = test_df[\"class\"]\n",
    "y_pred = test_df[\"pred\"]\n",
    "{\"accuracy\": accuracy_score(y_true, y_pred), \"f1\":f1_score(y_true,y_pred, average = \"macro\"),\"precision\":precision_score(y_true,y_pred,average = \"macro\"), \"recall\":recall_score(y_true,y_pred,average = \"macro\")}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without training the distilbert model on downstream task, the default distilbert model + classification head performs extremely poor. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning on custom data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = read_data(train_file, lower_case = True)\n",
    "labels = train_df[LABEL_COL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(train_df[TEXT_COL], train_df[LABEL_COL], test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = train_texts.tolist()\n",
    "val_texts = val_texts.tolist()\n",
    "train_labels= train_labels.tolist()\n",
    "val_labels= val_labels.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\",num_labels = 3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Tokenize the training and test text \n",
    "\n",
    "2) Turn the tokenized encodings and labels to Dataset obj in pytorch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True)\n",
    "#test_encodings = tokenizer(test_texts, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = customDataset(train_encodings, train_labels)\n",
    "val_dataset = customDataset(val_encodings, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training argument to be defined outside of class? \n",
    "# for together with arg_parse? \n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=10,              # total # of training epochs\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
    "    warmup_steps=50,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps = 20,\n",
    "    no_cuda = True\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model = model,\n",
    "                   args = training_args,\n",
    "                   train_dataset = train_dataset, \n",
    "                   eval_dataset = val_dataset,\n",
    "                    compute_metrics = compute_metrics)\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter('runs/sentiment_exp_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model using trainer \n",
    "trainer.save_model(\"../models/distilbert/model_config\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the tokenizer (you did not expand the vocab)\n",
    "tokenizer.save_pretrained('../models/distilbert/tokenizer_config')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model = new_model,\n",
    "                   args = training_args,\n",
    "                   train_dataset = train_dataset, \n",
    "                   eval_dataset = val_dataset,\n",
    "                    compute_metrics = compute_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running evaluation on Test dataset \n",
    "\n",
    "After we load a pre-trained model from our own directory or from huggingface, the model itself can be treated as a nn.module. \n",
    "\n",
    "This means that we can use it as it is in pytorch.\n",
    "See fine-tuning in native pytorch to help you. \n",
    "https://huggingface.co/transformers/training.html\n",
    "\n",
    "Models that are initialized are eval mode by default. We can then use pytorch's dataset and dataloader class to help us when we do evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from transformers import DistilBertTokenizerFast, Trainer, TrainingArguments, DistilBertForSequenceClassification \n",
    "from sklearn.metrics import accuracy_score, f1_score,precision_recall_fscore_support\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.functional import softmax\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = read_data(train_file,lower_case= True)\n",
    "labels = train_df[LABEL_COL].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tokenizer = DistilBertTokenizerFast.from_pretrained('../models/distilbert/tokenizer_config')\n",
    "test_model= DistilBertForSequenceClassification.from_pretrained(\"../models/distilbert/model_config\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = test_tokenizer(train_df[TEXT_COL].tolist(), truncation=True, padding=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_utils import customDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = customDataset(train_encodings, labels)\n",
    "dataloader = DataLoader(dataset = train_dataset, batch_size = 4, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model.to(device)\n",
    "# model output is logits \n",
    "# return df[\"score\"]\n",
    "# softmax all the logits to class\n",
    "# return df[\"pred\"]\n",
    "\n",
    "test_model.eval()\n",
    "\n",
    "# empty list for prediction to be appended into  \n",
    "pred_list = []\n",
    "with torch.no_grad():  # so will not update \n",
    "    \n",
    "    # tqdm for progress bar\n",
    "    loop = tqdm(enumerate(dataloader), total = len(dataloader),\n",
    "                        leave = True)\n",
    "    for _, data in loop:     \n",
    "        input_ids = data[\"input_ids\"].to(device)\n",
    "        masks = data[\"attention_mask\"].to(device)\n",
    "        labels = data[\"labels\"].to(device)\n",
    "        \n",
    "        outputs = test_model(input_ids, masks, labels = labels)\n",
    "        # information about model outputs: https://huggingface.co/transformers/main_classes/output.html\n",
    "\n",
    "        # sample output: \n",
    "        # SequenceClassifierOutput(loss=tensor(1.6602, device='cuda:0', grad_fn=<NllLossBackward>), \n",
    "        # logits=tensor([[-0.0098,  0.0775,  0.0358,  0.0997, -0.0220],\n",
    "        # [-0.0169,  0.1331,  0.0294,  0.1378,  0.0054]], device='cuda:0',\n",
    "        # grad_fn=<AddmmBackward>), hidden_states=None, attentions=None)\n",
    "   \n",
    "        logits = outputs[\"logits\"]\n",
    "        scores = softmax(logits, dim =1)\n",
    "        # numpy array of batch size \n",
    "        pred = torch.argmax(scores, dim =1).cpu().numpy().tolist()\n",
    "        # appends the batch pred into an empty list \n",
    "        pred_list.append(pred)\n",
    "    \n",
    "    # flatten the nested list in pred_list\n",
    "    flat_list = [item for sublist in pred_list for item in sublist]\n",
    "    \n",
    "    train_df[\"pred\"]= pd.Series(flat_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = train_df[\"class\"]\n",
    "y_pred = train_df[\"pred\"]\n",
    "{\"accuracy\": accuracy_score(y_true, y_pred), \"f1\":f1_score(y_true,y_pred, average = \"macro\"),\"precision\":precision_score(y_true,y_pred,average = \"macro\"), \"recall\":recall_score(y_true,y_pred,average = \"macro\")}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sentiment-torch-gpu] *",
   "language": "python",
   "name": "conda-env-sentiment-torch-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
